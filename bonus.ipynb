{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdlquHn6yY-D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from torchvision.datasets import ImageFolder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZNq4q_CyYXw",
        "outputId": "526b0d6d-5230-4ffa-8589-15a08c5db3d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['training', 'validation', 'evaluation']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zip_file_path = '/content/archive (10).zip'\n",
        "extract_folder = 'food11/'\n",
        "os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "extracted_files = os.listdir(extract_folder)\n",
        "extracted_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYijoQWqx0sq"
      },
      "outputs": [],
      "source": [
        "# Data Preparation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = ImageFolder(root='food11/training', transform=transform)\n",
        "validation_dataset = ImageFolder(root='food11/validation', transform=transform)\n",
        "test_dataset = ImageFolder(root='food11/evaluation', transform=transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDAAYaCt8BwB",
        "outputId": "37fe5d4f-37b6-46c2-da6b-d25764e0c11d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 150MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 95.7MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 166MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device cuda\n"
          ]
        }
      ],
      "source": [
        "# Choose Pre-trained Models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model1 = models.resnet18(pretrained=True)\n",
        "model2 = models.vgg16(pretrained=True)\n",
        "model3 = models.densenet121(pretrained=True)\n",
        "model_list = [model1, model2,model3]\n",
        "num_epochs=4\n",
        "print('Device',device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd914Kdcrf71",
        "outputId": "89447bc1-c9b0-4fdb-ac85-ac8a338eecb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model: ResNet\n",
            "Epoch:  1 Train Loss:  0.9526820285999273 Validation Loss:  0.5254220370617178\n",
            "Epoch:  2 Train Loss:  0.3949340412628303 Validation Loss:  0.42354226429705266\n",
            "Epoch:  3 Train Loss:  0.23502952241396055 Validation Loss:  0.3906392501322208\n",
            "Epoch:  4 Train Loss:  0.13966463221701217 Validation Loss:  0.37806591557131874\n",
            "Training model: VGG\n",
            "Epoch:  1 Train Loss:  0.7722503272846679 Validation Loss:  0.475217977469718\n",
            "Epoch:  2 Train Loss:  0.3857533823710815 Validation Loss:  0.45657368162991824\n",
            "Epoch:  3 Train Loss:  0.22905857132711602 Validation Loss:  0.38430024390281353\n",
            "Epoch:  4 Train Loss:  0.15143215842243635 Validation Loss:  0.4486834237834922\n",
            "Training model: DenseNet\n",
            "Epoch:  1 Train Loss:  0.8517075306871562 Validation Loss:  0.4087427127416487\n",
            "Epoch:  2 Train Loss:  0.3251675481404687 Validation Loss:  0.3354087009750031\n",
            "Epoch:  3 Train Loss:  0.18639068297053232 Validation Loss:  0.29840223249737863\n",
            "Epoch:  4 Train Loss:  0.10000566664998778 Validation Loss:  0.302742391479788\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "# Fine-tuning\n",
        "for model in model_list:\n",
        "    print('Training model:', model.__class__.__name__)\n",
        "    if model.__class__.__name__ == 'ResNet':\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, 11)\n",
        "\n",
        "    elif model.__class__.__name__ == 'VGG':\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, 11)\n",
        "\n",
        "    elif model.__class__.__name__ == 'DenseNet':\n",
        "        model.classifier = nn.Linear(model.classifier.in_features, 11)\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "          for inputs, labels in validation_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        val_losses.append(val_loss / len(validation_loader))\n",
        "\n",
        "        print(\"Epoch: \", epoch+1, \"Train Loss: \", train_loss/len(train_loader), \"Validation Loss: \" ,val_loss/len(validation_loader))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qMe8Hc1pQQGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53b881a-a4bc-4c6c-d75c-eb1c094bb4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing model: ResNet\n",
            "Accuracy of the network on the test images: 90 %\n",
            "Testing model: VGG\n",
            "Accuracy of the network on the test images: 89 %\n",
            "Testing model: DenseNet\n",
            "Accuracy of the network on the test images: 92 %\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "for model in model_list:\n",
        "    print('Testing model:', model.__class__.__name__)\n",
        "    model.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyRy0alw8Pl4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2AUXtvZDAjs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}